**a. Import required libraries**

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras import Model, Input
from tensorflow.keras.layers import Dense
from sklearn.model_selection import train_test_split




**b. Loading dataset**

assuming data is your dataset

Path_TO_DATA = 'https://storage.googleapis.com/download.tensorflow.org/data/ecg.csv'
data = pd.read_csv(Path_TO_DATA, header = None)


split data into test and train set

x_train, x_test = train_test_split(data, test_size = 0.2, random_state=42)



**c. Encoder**

input_img = x_train.shape[1]
encoder = tf.keras.Sequential([
    Dense(64, activation = "relu", input_shape = (input_img,)),
    Dense(32, activation = "relu"),
    Dense(16, activation = "relu")
])



**d. Decoder**

decoder = tf.keras.Sequential([
    Dense(32, activation = "relu", input_shape=(16,)),
    Dense(64, activation = "relu"),
    Dense(input_img, activation = "sigmoid")
])




**e. Compile and fit model**

# combine encoder and decoder into autoencoder model

autoencoder_input = Input(shape=(input_img,))
encoded = encoder(autoencoder_input)
decoded = decoder(encoded)
autoencoder = Model(autoencoder_input, decoded)


#compile model

autoencoder.compile(
    optimizer = "adam",
    loss = "mse"
)

autoencoder.fit( x_train, x_train, epochs = 20, batch_size = 32, shuffle = True, validation_data = (x_test, x_test))


# reconstruction loss

reconstruction_loss = autoencoder.evaluate(x_test, x_test)
print("Reconstruction Loss:", reconstruction_loss)


# anomaly detection

reconstructions = autoencoder.predict(x_test)
mse = np.mean(np.power(x_test - reconstructions, 2), axis=1)  # calculate mse per sample
threshold = np.mean(mse) + 3 * np.std(mse)  # threshold for reconstruction error

anomalies = np.where(mse > threshold)[0]
print("Indices of Anomalies:", anomalies)